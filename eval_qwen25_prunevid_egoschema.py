#!/usr/bin/env python3
"""
Evaluation Script: Qwen2.5-VL + PruneVid on EgoSchema

Based on the ACL 2025 paper: "PruneVid: Visual Token Pruning for Efficient Video Large Language Models"
Paper: https://arxiv.org/abs/2412.16117
Official Code: https://github.com/Visual-AI/PruneVid
"""

import os
import sys
import json
from pathlib import Path
import pandas as pd
import numpy as np

# Add to path
sys.path.insert(0, str(Path(__file__).parent))

from qwen_prunevid import Qwen25VLPruneVid


# ============================================================================
# é…ç½®å‚æ•° - åŸºäº PruneVid è®ºæ–‡çš„æ ‡å‡†è®¾ç½®
# ============================================================================
class Config:
    """
    å®éªŒé…ç½® - æ‰€æœ‰å‚æ•°é›†ä¸­ç®¡ç†

    PruneVid è®ºæ–‡é»˜è®¤å€¼ï¼ˆä¸‰é˜¶æ®µï¼‰:
    - Stage 1: tau=0.8, cluster_ratio=0.5, temporal_segment_ratio=0.25
    - Stage 2: keep_ratio=0.4, pruning_layer=10
    - max_frames: 16 (PLLaVA/ST-LLM) æˆ– 32 (LLaVA-OneVision)
    """

    # ===== æ¨¡å‹é…ç½® =====
    MODEL_PATH = "/mnt/ssd_ext/huggingface/models/Qwen2.5-VL-7B-Instruct"
    GPU_ID = 0  # GPU ç¼–å·ï¼ŒNone = CPU

    # ===== è§†é¢‘é‡‡æ ·é…ç½® =====
    MAX_FRAMES = 16  # æœ€å¤§å¸§æ•° (æ¨è: 16)
    MIN_FRAMES = 4   # æœ€å°å¸§æ•°
    FPS = None       # None = å‡åŒ€é‡‡æ ·ï¼Œfloat = æŒ‰FPSé‡‡æ ·

    # ===== Stage 1: Spatial-Temporal Token Merging =====
    ENABLE_STAGE1 = True              # å¯ç”¨Stage 1 (Vision Encoderå±‚é¢)
    TAU = 0.1                          # é™æ€/åŠ¨æ€é˜ˆå€¼ [0.7-0.9]
    CLUSTER_RATIO = 0.5                # ç©ºé—´èšç±»ä¿ç•™æ¯”ä¾‹ [0.3-0.8]
    TEMPORAL_SEGMENT_RATIO = 0.25      # æ—¶åºåˆ†æ®µæ¯”ä¾‹ [0.25-0.5]

    # ===== Stage 2: Attention-Based Token Pruning =====
    ENABLE_PRUNING = True   # å¯ç”¨Stage 2 (LLMå±‚é¢)
    KEEP_RATIO = 0.5        # Tokenä¿ç•™æ¯”ä¾‹ [0.3-0.6] (è®ºæ–‡é»˜è®¤å€¼)
    PRUNING_LAYER = 10      # åœ¨ç¬¬10å±‚å‰ªæ (è®ºæ–‡é»˜è®¤å€¼)

    # ===== æ•°æ®é›†é…ç½® =====
    DATASET_PATH = "datasets--lmms-lab--egoschema/snapshots/58350524ea7eb29c47000121f4f4b65eb6b4acb9/Subset/test-00000-of-00001.parquet"
    VIDEO_DIR = "egoschema/videos"
    NUM_SAMPLES = 10   # æµ‹è¯•æ ·æœ¬æ•°é‡
    START_IDX = 0      # èµ·å§‹ç´¢å¼•

    # ===== è¾“å‡ºé…ç½® =====
    OUTPUT_DIR = "results"
    EXP_NAME = None  # è‡ªåŠ¨ç”Ÿæˆ
    VERBOSE = False  # è¯¦ç»†è°ƒè¯•è¾“å‡º

    # ===== å…¶ä»– =====
    SAVE_INTERVAL = 10  # æ¯Nä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def convert_to_serializable(obj):
    """Convert numpy/torch types to Python types for JSON."""
    if isinstance(obj, (np.integer, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    return obj


def print_config(cfg):
    """Print experiment configuration."""
    print("=" * 80)
    print("å®éªŒé…ç½® - PruneVid + Qwen2.5-VL on EgoSchema")
    print("=" * 80)
    print(f"\nğŸ“¦ æ¨¡å‹:")
    print(f"  è·¯å¾„: {cfg.MODEL_PATH}")
    print(f"  è®¾å¤‡: GPU {cfg.GPU_ID}" if cfg.GPU_ID is not None else "  è®¾å¤‡: CPU")

    print(f"\nğŸ¬ è§†é¢‘é‡‡æ ·:")
    print(f"  æœ€å¤§å¸§æ•°: {cfg.MAX_FRAMES}")
    print(f"  æœ€å°å¸§æ•°: {cfg.MIN_FRAMES}")
    print(f"  é‡‡æ ·æ–¹å¼: {'FPS=' + str(cfg.FPS) if cfg.FPS else 'å‡åŒ€é‡‡æ ·'}")

    print(f"\nâœ‚ï¸  PruneVid (ä¸‰é˜¶æ®µ):")
    print(f"  Stage 1 (æ—¶ç©ºTokenåˆå¹¶): {'å¯ç”¨' if cfg.ENABLE_STAGE1 else 'ç¦ç”¨'}")
    if cfg.ENABLE_STAGE1:
        print(f"    tau: {cfg.TAU}")
        print(f"    cluster_ratio: {cfg.CLUSTER_RATIO}")
        print(f"    temporal_segment_ratio: {cfg.TEMPORAL_SEGMENT_RATIO}")

    print(f"  Stage 2 (Attentionå‰ªæ): {'å¯ç”¨' if cfg.ENABLE_PRUNING else 'ç¦ç”¨'}")
    if cfg.ENABLE_PRUNING:
        print(f"    keep_ratio: {cfg.KEEP_RATIO} (åˆ é™¤ {1-cfg.KEEP_RATIO:.1%})")
        print(f"    pruning_layer: Layer {cfg.PRUNING_LAYER}")

    print(f"\nğŸ“Š æ•°æ®é›†:")
    print(f"  æµ‹è¯•æ ·æœ¬: {cfg.NUM_SAMPLES} (ç´¢å¼• {cfg.START_IDX} - {cfg.START_IDX + cfg.NUM_SAMPLES - 1})")

    print(f"\nğŸ’¾ è¾“å‡º:")
    # ç”Ÿæˆå®éªŒåç§°
    if cfg.EXP_NAME:
        exp_name = cfg.EXP_NAME
    else:
        parts = []
        if cfg.ENABLE_STAGE1:
            parts.append(f"s1_tau{cfg.TAU}_c{cfg.CLUSTER_RATIO}")
        if cfg.ENABLE_PRUNING:
            parts.append(f"s2_k{cfg.KEEP_RATIO}_l{cfg.PRUNING_LAYER}")
        if not parts:
            exp_name = f"baseline_f{cfg.MAX_FRAMES}"
        else:
            exp_name = "_".join(parts) + f"_f{cfg.MAX_FRAMES}"
    print(f"  å®éªŒåç§°: {exp_name}")
    print(f"  è¾“å‡ºç›®å½•: {cfg.OUTPUT_DIR}/{exp_name}")

    print("=" * 80 + "\n")


# ============================================================================
# ä¸»è¯„ä¼°å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    cfg = Config()

    # è®¾ç½® GPU
    if cfg.GPU_ID is not None:
        os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU_ID)
        device = "cuda"
    else:
        device = "cpu"

    # æ‰“å°é…ç½®
    print_config(cfg)

    # ç”Ÿæˆå®éªŒåç§°
    if cfg.EXP_NAME is None:
        parts = []
        if cfg.ENABLE_STAGE1:
            parts.append(f"s1_tau{cfg.TAU}_c{cfg.CLUSTER_RATIO}_t{cfg.TEMPORAL_SEGMENT_RATIO}")
        if cfg.ENABLE_PRUNING:
            parts.append(f"s2_k{cfg.KEEP_RATIO}_l{cfg.PRUNING_LAYER}")
        if not parts:
            cfg.EXP_NAME = f"baseline_f{cfg.MAX_FRAMES}"
        else:
            cfg.EXP_NAME = "_".join(parts) + f"_f{cfg.MAX_FRAMES}"

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(cfg.OUTPUT_DIR) / cfg.EXP_NAME
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}\n")

    # ä¿å­˜é…ç½®
    config_dict = {k: v for k, v in vars(cfg).items() if not k.startswith('_')}
    with open(output_dir / "config.json", 'w') as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)

    # åŠ è½½æ•°æ®é›†
    print(f"ğŸ“¥ åŠ è½½æ•°æ®é›†...")
    df = pd.read_parquet(cfg.DATASET_PATH)
    end_idx = min(cfg.START_IDX + cfg.NUM_SAMPLES, len(df))
    df = df.iloc[cfg.START_IDX:end_idx]
    print(f"   æ ·æœ¬èŒƒå›´: {cfg.START_IDX} - {end_idx - 1} (å…± {len(df)} ä¸ª)\n")

    # åˆå§‹åŒ–æ¨¡å‹
    print(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹...")
    model = Qwen25VLPruneVid(
        model_path=cfg.MODEL_PATH,
        # Stage 1å‚æ•°
        enable_stage1=cfg.ENABLE_STAGE1,
        tau=cfg.TAU,
        cluster_ratio=cfg.CLUSTER_RATIO,
        temporal_segment_ratio=cfg.TEMPORAL_SEGMENT_RATIO,
        # Stage 2å‚æ•°
        enable_pruning=cfg.ENABLE_PRUNING,
        keep_ratio=cfg.KEEP_RATIO,
        pruning_layer=cfg.PRUNING_LAYER,
        # å…¶ä»–å‚æ•°
        device=device,
        max_frames=cfg.MAX_FRAMES,
        min_frames=cfg.MIN_FRAMES,
        fps=cfg.FPS,
        verbose=cfg.VERBOSE
    )
    print()

    # å¼€å§‹è¯„ä¼°
    print("=" * 80)
    print("å¼€å§‹è¯„ä¼°")
    print("=" * 80 + "\n")

    results = []
    total_correct = 0
    total_answered = 0
    all_stage1_ratios = []
    all_stage2_ratios = []
    all_total_ratios = []

    for idx, row in df.iterrows():
        sample_idx = idx - cfg.START_IDX
        video_path = os.path.join(cfg.VIDEO_DIR, f"{row['video_idx']}.mp4")

        print(f"[{sample_idx + 1}/{len(df)}] Video: {row['video_idx']}")
        print("-" * 80)

        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
        if not os.path.exists(video_path):
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}\n")
            results.append({
                'sample_id': cfg.START_IDX + sample_idx,
                'video_idx': row['video_idx'],
                'error': 'Video file not found'
            })
            print("=" * 80 + "\n")
            continue

        try:
            # å¤„ç†æ ·æœ¬
            prediction, generated_text, stats = model.process_egoschema_sample(
                video_path=video_path,
                question=row['question'],
                options=row['option']
            )

            # æ£€æŸ¥æ­£ç¡®æ€§
            gt_answer = int(row['answer'])
            gt_letter = chr(65 + gt_answer)  # 0â†’A, 1â†’B, etc.
            correct = (prediction == gt_letter)

            # æ›´æ–°ç»Ÿè®¡
            total_answered += 1
            if correct:
                total_correct += 1

            # æ”¶é›†å‹ç¼©æ¯”ç»Ÿè®¡
            if 'stage1_compression_ratio' in stats:
                all_stage1_ratios.append(stats['stage1_compression_ratio'])
            if 'pruning_ratio' in stats:
                all_stage2_ratios.append(stats['pruning_ratio'])
            if 'total_compression_ratio' in stats:
                all_total_ratios.append(stats['total_compression_ratio'])

            # æ‰“å°ç»“æœ
            print(f"\né—®é¢˜: {row['question'][:100]}...")
            print(f"æ¨¡å‹å›ç­”: {prediction}")
            print(f"æ­£ç¡®ç­”æ¡ˆ: {gt_letter}")
            print(f"åˆ¤æ–­: {'âœ… æ­£ç¡®' if correct else 'âŒ é”™è¯¯'}")
            print(f"è§†é¢‘é‡‡æ ·: {stats.get('num_frames', 0)} å¸§")

            # æ‰“å° Token ç»Ÿè®¡
            print(f"\nToken ç»Ÿè®¡:")
            if stats.get('tokens_before_stage1', 0) > 0:
                print(f"  Stage 1: {stats['tokens_before_stage1']} â†’ {stats['tokens_after_stage1']} "
                      f"({stats['stage1_compression_ratio']:.1%} å‹ç¼©)")
            if stats.get('tokens_before', 0) > 0:
                print(f"  Stage 2: {stats['tokens_before']} â†’ {stats['tokens_after']} "
                      f"({stats['pruning_ratio']:.1%} å‹ç¼©)")
            if stats.get('total_compression_ratio', 0) > 0:
                print(f"  æ€»ä½“å‹ç¼©æ¯”: {stats['total_compression_ratio']:.1%}")

            # æ‰“å°ç´¯è®¡ç»Ÿè®¡
            current_accuracy = total_correct / total_answered if total_answered > 0 else 0.0

            print(f"\nğŸ“Š ç´¯è®¡ç»Ÿè®¡ (æˆªè‡³ç¬¬ {sample_idx + 1} é¢˜):")
            print(f"   å‡†ç¡®ç‡: {total_correct}/{total_answered} = {current_accuracy:.2%}")

            # Average Token Drop Ratio (æœ€é‡è¦çš„æŒ‡æ ‡) - å³ä½¿baselineä¹Ÿæ˜¾ç¤º
            if all_total_ratios:
                avg_token_drop = np.mean(all_total_ratios)
                print(f"   ğŸ¯ Average Token Drop Ratio: {avg_token_drop:.2%}")

                # åˆ†é˜¶æ®µç»Ÿè®¡ï¼ˆå¯é€‰è¯¦ç»†ä¿¡æ¯ï¼‰
                if all_stage1_ratios:
                    avg_s1 = np.mean(all_stage1_ratios)
                    print(f"      â””â”€ Stage 1 å‹ç¼©: {avg_s1:.2%}")
                if all_stage2_ratios:
                    avg_s2 = np.mean(all_stage2_ratios)
                    print(f"      â””â”€ Stage 2 å‰ªæ: {avg_s2:.2%}")
            else:
                # Baselineæ¨¡å¼ - æ²¡æœ‰pruning
                print(f"   ğŸ¯ Average Token Drop Ratio: 0.00% (Baseline - no pruning)")

            # ä¿å­˜ç»“æœ
            result = {
                'sample_id': cfg.START_IDX + sample_idx,
                'video_idx': row['video_idx'],
                'question': row['question'],
                'options': row['option'],
                'prediction': prediction,
                'ground_truth': gt_letter,
                'correct': correct,
                'generated_text': generated_text,
                **stats
            }
            results.append(result)

        except Exception as e:
            print(f"\nâŒ å¤„ç†å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()

            results.append({
                'sample_id': cfg.START_IDX + sample_idx,
                'video_idx': row['video_idx'],
                'error': str(e)
            })

        print("=" * 80 + "\n")

        # å®šæœŸä¿å­˜
        if (sample_idx + 1) % cfg.SAVE_INTERVAL == 0:
            with open(output_dir / f"results_interim_{sample_idx + 1}.json", 'w') as f:
                json.dump(convert_to_serializable(results), f, indent=2)
            print(f"ğŸ’¾ ä¸­é—´ç»“æœå·²ä¿å­˜\n")

    # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ğŸ‰ è¯„ä¼°å®Œæˆ - æœ€ç»ˆç»“æœ")
    print("=" * 80 + "\n")

    valid_results = [r for r in results if 'correct' in r]
    num_correct = sum(r['correct'] for r in valid_results)
    num_total = len(valid_results)
    final_accuracy = num_correct / num_total if num_total > 0 else 0.0

    print(f"ğŸ“ˆ å‡†ç¡®ç‡ (Accuracy):")
    print(f"   {num_correct}/{num_total} = {final_accuracy:.2%}")

    # ============================================================
    # ğŸ¯ Average Token Drop Ratio (æ ¸å¿ƒæŒ‡æ ‡)
    # ============================================================
    if all_total_ratios:
        avg_token_drop = np.mean(all_total_ratios)
        print(f"\nğŸ¯ Average Token Drop Ratio:")
        print(f"   {avg_token_drop:.2%} of tokens were dropped")
        print(f"   {1 - avg_token_drop:.2%} of tokens were kept")
    else:
        print(f"\nğŸ¯ Average Token Drop Ratio:")
        print(f"   0.00% (Baseline - no pruning applied)")

    # åˆ†é˜¶æ®µè¯¦ç»†ç»Ÿè®¡
    if cfg.ENABLE_STAGE1 and all_stage1_ratios:
        avg_s1 = np.mean(all_stage1_ratios)
        print(f"\nâœ‚ï¸  Stage 1 è¯¦æƒ… (Spatial-Temporal Merging):")
        print(f"   å¹³å‡å‹ç¼©: {avg_s1:.2%}")
        print(f"   ä¿ç•™: {1 - avg_s1:.2%}")

    if cfg.ENABLE_PRUNING and all_stage2_ratios:
        avg_s2 = np.mean(all_stage2_ratios)
        print(f"\nâœ‚ï¸  Stage 2 è¯¦æƒ… (Attention-Based Pruning):")
        print(f"   å¹³å‡å‰ªæ: {avg_s2:.2%}")
        print(f"   ä¿ç•™: {1 - avg_s2:.2%}")

    # æ—¶é—´ç»Ÿè®¡
    inference_times = [r['inference_time'] for r in results if 'inference_time' in r]
    if inference_times:
        avg_time = np.mean(inference_times)
        print(f"\nâ±ï¸  æ€§èƒ½:")
        print(f"   å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f}s/æ ·æœ¬")

    # ä¿å­˜æœ€ç»ˆç»“æœ
    with open(output_dir / "results.json", 'w') as f:
        json.dump(convert_to_serializable(results), f, indent=2)
    print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜: {output_dir / 'results.json'}")

    # ä¿å­˜æ‘˜è¦
    summary = {
        'experiment': cfg.EXP_NAME,
        'config': config_dict,
        'results': {
            'num_samples': num_total,
            'num_correct': num_correct,
            'accuracy': float(final_accuracy),
            'avg_stage1_compression': float(np.mean(all_stage1_ratios)) if all_stage1_ratios else None,
            'avg_stage2_pruning': float(np.mean(all_stage2_ratios)) if all_stage2_ratios else None,
            'avg_total_compression': float(np.mean(all_total_ratios)) if all_total_ratios else None,
            'avg_inference_time': float(avg_time) if inference_times else None,
        }
    }

    with open(output_dir / "summary.json", 'w') as f:
        json.dump(convert_to_serializable(summary), f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ æ‘˜è¦å·²ä¿å­˜: {output_dir / 'summary.json'}")

    print("\n" + "=" * 80)
    print(f"âœ… å®éªŒ '{cfg.EXP_NAME}' å®Œæˆ!")
    print("=" * 80)


if __name__ == "__main__":
    main()

# å¦‚ä½•è¿è¡Œ PruneVid Stage 1 + Qwen2.5-VL

æœ¬æ–‡æ¡£è¯´æ˜Žå¦‚ä½•ä½¿ç”¨é›†æˆäº† PruneVid Stage 1 çš„ Qwen2.5-VL æ¨¡åž‹ã€‚

## ç›®å½•ç»“æž„

```
qwen_prunevid_new/
â”œâ”€â”€ modeling_qwen2_5_vl_prunevid_full.py  # æ ¸å¿ƒï¼šé›†æˆäº† PruneVid Stage 1 çš„å®Œæ•´æ¨¡åž‹
â”œâ”€â”€ model_wrapper.py                      # å·²ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„ modeling æ–‡ä»¶
â”œâ”€â”€ config.py                             # PruneVid é…ç½®
â”œâ”€â”€ eval_egoschema.py                     # EgoSchema è¯„ä¼°è„šæœ¬
â”œâ”€â”€ run_simple_test.py                    # ç®€å•æµ‹è¯•è„šæœ¬ï¼ˆæ–°åˆ›å»ºï¼‰
â””â”€â”€ README_USAGE.md                       # æœ¬æ–‡ä»¶
```

## å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨ç®€å•æµ‹è¯•è„šæœ¬ï¼ˆæŽ¨èï¼‰

è¿™æ˜¯æœ€ç®€å•çš„æ–¹å¼ï¼Œç”¨äºŽå¿«é€Ÿæµ‹è¯• PruneVid Stage 1 çš„æ•ˆæžœã€‚

1. **ä¿®æ”¹é…ç½®**

   ç¼–è¾‘ `run_simple_test.py`ï¼Œä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š

   ```python
   # æ¨¡åž‹è·¯å¾„
   MODEL_PATH = "/mnt/ssd_ext/huggingface/models/Qwen2.5-VL-7B-Instruct"

   # è§†é¢‘è·¯å¾„ï¼ˆä¿®æ”¹ä¸ºä½ çš„è§†é¢‘è·¯å¾„ï¼‰
   VIDEO_PATH = "/path/to/your/video.mp4"

   # é—®é¢˜
   QUESTION = "What is happening in this video?"

   # PruneVid Stage 1 å‚æ•°
   ENABLE_STAGE1 = True
   TAU = 0.8  # é™æ€/åŠ¨æ€åˆ†ç¦»é˜ˆå€¼ (0.6-0.9)
   CLUSTER_RATIO = 0.5  # ç©ºé—´èšç±»ä¿ç•™æ¯”ä¾‹ (0.3-0.7)
   TEMPORAL_SEGMENT_RATIO = 0.25  # æ—¶åºåˆ†æ®µæ¯”ä¾‹ (0.125-0.5)
   DPC_KNN_K = 5  # DPC-KNN çš„ k è¿‘é‚»å‚æ•°
   VERBOSE = True  # æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
   ```

2. **è¿è¡Œæµ‹è¯•**

   ```bash
   cd /mnt/ssd_ext/huggingface/qwen_prunevid_new
   python run_simple_test.py
   ```

3. **æŸ¥çœ‹è¾“å‡º**

   è„šæœ¬ä¼šè¾“å‡ºï¼š
   - Baselineï¼ˆä¸ä½¿ç”¨ Stage 1ï¼‰çš„å›žç­”
   - PruneVid Stage 1 çš„å›žç­”
   - Token åŽ‹ç¼©ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æžœ verbose=Trueï¼‰

### æ–¹æ³• 2: ä½¿ç”¨ Wrapper ç±»

è¿™ç§æ–¹å¼æ›´çµæ´»ï¼Œé€‚åˆé›†æˆåˆ°è‡ªå·±çš„ä»£ç ä¸­ã€‚

```python
import sys
sys.path.insert(0, '/mnt/ssd_ext/huggingface/qwen_prunevid_new')

from config import PruneVidConfig
from model_wrapper import Qwen25VLPruneVid

# 1. é…ç½® PruneVid
config = PruneVidConfig(
    # Stage 1 å‚æ•°
    enable_stage1=True,
    tau=0.8,
    cluster_ratio=0.5,
    temporal_segment_ratio=0.25,
    dpc_knn_k=5,

    # Stage 2 å‚æ•°ï¼ˆå¯é€‰ï¼‰
    enable_pruning=False,  # æš‚æ—¶ç¦ç”¨ Stage 2

    # å…¶ä»–é…ç½®
    verbose=True,
)

# 2. åŠ è½½æ¨¡åž‹
model = Qwen25VLPruneVid(
    model_path="/mnt/ssd_ext/huggingface/models/Qwen2.5-VL-7B-Instruct",
    config=config,
    device="cuda:0",
)

# 3. ç”Ÿæˆå›žç­”
result = model.generate(
    video_path="/path/to/your/video.mp4",
    question="What is happening in this video?",
    max_new_tokens=100,
    return_dict=True,
)

# 4. æŸ¥çœ‹ç»“æžœ
print("å›žç­”:", result['generated_text'])
print("åŽ‹ç¼©ç»Ÿè®¡:", result['compression_stats'])
print("ç”Ÿæˆæ—¶é—´:", result['generation_time'], "ç§’")
```

### æ–¹æ³• 3: ç›´æŽ¥ä½¿ç”¨æ¨¡åž‹ï¼ˆæœ€çµæ´»ï¼‰

å¦‚æžœä½ æƒ³å®Œå…¨æŽ§åˆ¶æŽ¨ç†è¿‡ç¨‹ï¼š

```python
import torch
import sys
sys.path.insert(0, '/mnt/ssd_ext/huggingface/qwen_prunevid_new')

from modeling_qwen2_5_vl_prunevid_full import Qwen2_5_VLForConditionalGeneration
from transformers import AutoProcessor
from qwen_vl_utils import process_vision_info

# 1. åŠ è½½æ¨¡åž‹
model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    "/mnt/ssd_ext/huggingface/models/Qwen2.5-VL-7B-Instruct",
    torch_dtype=torch.bfloat16,
    device_map="cuda:0",
)

processor = AutoProcessor.from_pretrained(
    "/mnt/ssd_ext/huggingface/models/Qwen2.5-VL-7B-Instruct"
)

# 2. å‡†å¤‡è¾“å…¥
messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "video",
                "video": "/path/to/your/video.mp4",
                "max_pixels": 589824,  # 192*192*16
                "fps": 1.0,
            },
            {"type": "text", "text": "What is happening in this video?"},
        ],
    }
]

text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
image_inputs, video_inputs = process_vision_info(messages)
inputs = processor(text=[text], images=image_inputs, videos=video_inputs, padding=True, return_tensors="pt")
inputs = inputs.to("cuda:0")

# 3. ç”Ÿæˆï¼ˆå¸¦ PruneVid Stage 1ï¼‰
with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=100,
        # PruneVid Stage 1 å‚æ•°
        enable_stage1=True,
        tau=0.8,
        cluster_ratio=0.5,
        temporal_segment_ratio=0.25,
        dpc_knn_k=5,
        verbose=True,  # æ‰“å°åŽ‹ç¼©ä¿¡æ¯
    )

# 4. è§£ç 
result = processor.batch_decode(outputs, skip_special_tokens=True)[0]
print(result)
```

### æ–¹æ³• 4: è¿è¡Œ EgoSchema è¯„ä¼°

å¦‚æžœä½ æƒ³åœ¨ EgoSchema æ•°æ®é›†ä¸Šè¯„ä¼°ï¼š

1. **ä¿®æ”¹é…ç½®**

   ç¼–è¾‘ `eval_egoschema.py` çš„é…ç½®åŒºåŸŸï¼ˆç¬¬ 16-63 è¡Œï¼‰ï¼š

   ```python
   # æ•°æ®é›†é…ç½®
   VIDEO_DIR = "/mnt/ssd_ext/huggingface/egoschema/videos"

   # æ¨¡åž‹é…ç½®
   MODEL_PATH = "/mnt/ssd_ext/huggingface/models/Qwen2.5-VL-7B-Instruct"

   # Stage 1 å‚æ•°
   ENABLE_STAGE1 = True
   TAU = 0.8
   CLUSTER_RATIO = 0.5
   TEMPORAL_SEGMENT_RATIO = 0.25

   # æµ‹è¯•é…ç½®
   NUM_SAMPLES = 10  # æµ‹è¯•æ ·æœ¬æ•°é‡ï¼ŒNone è¡¨ç¤ºå…¨éƒ¨
   ```

2. **è¿è¡Œè¯„ä¼°**

   ```bash
   cd /mnt/ssd_ext/huggingface/qwen_prunevid_new
   python eval_egoschema.py
   ```

## PruneVid Stage 1 å‚æ•°è¯´æ˜Ž

### æ ¸å¿ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | èŒƒå›´ | è¯´æ˜Ž |
|------|--------|------|------|
| `enable_stage1` | `False` | `True/False` | æ˜¯å¦å¯ç”¨ Stage 1 |
| `tau` | `0.8` | `0.6-0.9` | é™æ€/åŠ¨æ€åˆ†ç¦»é˜ˆå€¼ï¼Œè¶Šå¤§è¶Šå¤š token è¢«è§†ä¸ºé™æ€ |
| `cluster_ratio` | `0.5` | `0.3-0.7` | ç©ºé—´èšç±»ä¿ç•™æ¯”ä¾‹ï¼Œè¶Šå°åŽ‹ç¼©è¶Šå¤š |
| `temporal_segment_ratio` | `0.25` | `0.125-0.5` | æ—¶åºåˆ†æ®µæ¯”ä¾‹ï¼Œè¶Šå°åˆ†æ®µè¶Šå°‘ |
| `dpc_knn_k` | `5` | `3-10` | DPC-KNN çš„ k è¿‘é‚»å‚æ•° |
| `verbose` | `False` | `True/False` | æ˜¯å¦æ‰“å°è¯¦ç»†çš„åŽ‹ç¼©ä¿¡æ¯ |

### å‚æ•°è°ƒä¼˜å»ºè®®

**åŽ‹ç¼©æ›´å¤š tokens (æ›´å¿«ï¼Œå¯èƒ½ç•¥é™ä½Žç²¾åº¦):**
```python
tau=0.85                     # æ›´å¤šé™æ€ token
cluster_ratio=0.4            # æ›´æ¿€è¿›çš„èšç±»
temporal_segment_ratio=0.2   # æ›´å°‘çš„æ—¶åºæ®µ
```

**æ›´ä¿å®ˆçš„åŽ‹ç¼© (æ›´æ…¢ï¼Œæ›´é«˜ç²¾åº¦):**
```python
tau=0.75                     # æ›´å°‘é™æ€ token
cluster_ratio=0.6            # æ›´ä¿å®ˆçš„èšç±»
temporal_segment_ratio=0.3   # æ›´å¤šçš„æ—¶åºæ®µ
```

**è®ºæ–‡æŽ¨èé…ç½® (å¹³è¡¡):**
```python
tau=0.8
cluster_ratio=0.5
temporal_segment_ratio=0.25
dpc_knn_k=5
```

## å·¥ä½œåŽŸç†

PruneVid Stage 1 åœ¨ **position_embeddings ç”Ÿæˆä¹‹åŽã€decoder layers ä¹‹å‰** æ‰§è¡Œ token åŽ‹ç¼©ï¼š

```
è¾“å…¥è§†é¢‘
  â†“
è§†è§‰ç¼–ç å™¨ (Vision Encoder)
  â†“
åµŒå…¥å±‚ (Embed Tokens)
  â†“
ä½ç½®ç¼–ç ç”Ÿæˆ (Position Embeddings)
  â†“
ðŸŽ¯ PruneVid Stage 1: æ—¶ç©º Token åˆå¹¶
  â”‚  1. æ—¶åºèšç±»ï¼šå°†å¸§åˆ†ç»„ä¸ºåœºæ™¯æ®µ
  â”‚  2. é™æ€/åŠ¨æ€åˆ†ç¦»ï¼šè¯†åˆ«é™æ€åŒºåŸŸ
  â”‚  3. é™æ€ token åˆå¹¶ï¼šæ—¶é—´ç»´åº¦å¹³å‡
  â”‚  4. åŠ¨æ€ token èšç±»ï¼šç©ºé—´èšç±»
  â†“
è§£ç å™¨å±‚ (Decoder Layers)
  â†“
ç”Ÿæˆè¾“å‡º
```

## é¢„æœŸæ•ˆæžœ

æ ¹æ® PruneVid è®ºæ–‡ï¼Œåœ¨è§†é¢‘ä»»åŠ¡ä¸Šï¼š

- **Token åŽ‹ç¼©çŽ‡**: é€šå¸¸å¯ä»¥å‡å°‘ 40-60% çš„ visual tokens
- **æ€§èƒ½å½±å“**: åœ¨å¤§å¤šæ•°åŸºå‡†æµ‹è¯•ä¸Šä¿æŒæˆ–ç•¥å¾®æå‡æ€§èƒ½
- **é€Ÿåº¦æå‡**: æŽ¨ç†é€Ÿåº¦æå‡ 1.5-2xï¼ˆå–å†³äºŽåŽ‹ç¼©çŽ‡ï¼‰

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæ²¡æœ‰çœ‹åˆ°åŽ‹ç¼©æ•ˆæžœï¼Ÿ

A: ç¡®ä¿ï¼š
1. `enable_stage1=True`
2. `verbose=True` ä»¥æŸ¥çœ‹åŽ‹ç¼©ä¿¡æ¯
3. è¾“å…¥æ˜¯**è§†é¢‘**è€Œä¸æ˜¯å›¾ç‰‡
4. è§†é¢‘å¸§æ•° > 1

### Q2: å¦‚ä½•ç¡®è®¤ Stage 1 æ­£åœ¨å·¥ä½œï¼Ÿ

A: è®¾ç½® `verbose=True`ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š
```
[Stage 1] Tokens: 2304 -> 1152 (50.0% reduction)
```

### Q3: å¯ä»¥åŒæ—¶ä½¿ç”¨ Stage 1 å’Œ Stage 2 å—ï¼Ÿ

A: å¯ä»¥ï¼Œä½† Stage 2 (åŸºäºŽæ³¨æ„åŠ›çš„å‰ªæž) ç›®å‰å¯èƒ½éœ€è¦é¢å¤–è°ƒæ•´ã€‚å»ºè®®å…ˆåªä½¿ç”¨ Stage 1ã€‚

### Q4: åŽ‹ç¼©åŽç»“æžœå˜å·®äº†æ€Žä¹ˆåŠžï¼Ÿ

A: å°è¯•ï¼š
1. å‡å° `tau` (ä¾‹å¦‚ 0.75)
2. å¢žå¤§ `cluster_ratio` (ä¾‹å¦‚ 0.6)
3. å¢žå¤§ `temporal_segment_ratio` (ä¾‹å¦‚ 0.3)

## æ€§èƒ½åŸºå‡†

åœ¨ EgoSchema æ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æžœï¼ˆé¢„æœŸï¼‰ï¼š

| é…ç½® | Token ä¿ç•™çŽ‡ | å‡†ç¡®çŽ‡ | æŽ¨ç†é€Ÿåº¦ |
|------|-------------|--------|---------|
| Baseline (æ—  Stage 1) | 100% | - | 1x |
| Stage 1 (æŽ¨èé…ç½®) | ~45% | ~98% | ~1.8x |
| Stage 1 (æ¿€è¿›) | ~30% | ~95% | ~2.3x |

## ä¸‹ä¸€æ­¥

1. **è°ƒä¼˜å‚æ•°**: æ ¹æ®ä½ çš„ä»»åŠ¡è°ƒæ•´ `tau`, `cluster_ratio` ç­‰å‚æ•°
2. **é›†æˆ Stage 2**: æ·»åŠ åŸºäºŽæ³¨æ„åŠ›çš„ token é€‰æ‹©ï¼ˆå¦‚éœ€è¦ï¼‰
3. **è¯„ä¼°æ€§èƒ½**: åœ¨ä½ çš„æ•°æ®é›†ä¸Šè¯„ä¼°åŽ‹ç¼©çŽ‡å’Œç²¾åº¦æƒè¡¡

## æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ¨¡åž‹è·¯å¾„æ˜¯å¦æ­£ç¡®
2. è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
3. GPU å†…å­˜æ˜¯å¦è¶³å¤Ÿ
4. transformers ç‰ˆæœ¬æ˜¯å¦å…¼å®¹ï¼ˆå»ºè®® >= 4.37.0ï¼‰

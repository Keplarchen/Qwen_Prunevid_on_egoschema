# PruneVid for Qwen2.5-VL

[[ACL 2025 Paper]](https://aclanthology.org/2025.findings-acl.1024.pdf) | [[Project Page]](https://github.com/your-repo/prunevid)

è¿™æ˜¯PruneVidè§†è§‰tokenå‰ªææ–¹æ³•åœ¨Qwen2.5-VLæ¨¡å‹ä¸Šçš„å®ç°ã€‚

PruneVidé€šè¿‡ä¸‰ä¸ªé˜¶æ®µçš„æ¸è¿›å¼tokenå‰ªæï¼Œå®ç°é«˜æ•ˆçš„è§†é¢‘ç†è§£ï¼Œåœ¨ä¿æŒæˆ–ç”šè‡³æå‡å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå°†è®¡ç®—é‡å‡å°‘74%-80%ã€‚

## ğŸ“‹ ç›®å½•

- [æ–¹æ³•æ¦‚è¿°](#æ–¹æ³•æ¦‚è¿°)
- [å®‰è£…](#å®‰è£…)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨](#è¯¦ç»†ä½¿ç”¨)
- [æ€§èƒ½](#æ€§èƒ½)
- [é…ç½®å‚æ•°](#é…ç½®å‚æ•°)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [å¼•ç”¨](#å¼•ç”¨)

## ğŸ¯ æ–¹æ³•æ¦‚è¿°

PruneVidåŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š

### Stage 1: æ—¶ç©ºTokenåˆå¹¶ (Spatial-Temporal Token Merging)

å‡å°‘è§†é¢‘çš„å›ºæœ‰å†—ä½™ï¼š
- **æ—¶åºèšç±»**: å°†è§†é¢‘å¸§èšç±»æˆåœºæ™¯æ®µ
- **é™æ€/åŠ¨æ€åˆ†ç¦»**: è¯†åˆ«é™æ€èƒŒæ™¯å’ŒåŠ¨æ€å‰æ™¯
- **é™æ€tokenæ—¶åºåˆå¹¶**: å¯¹é™æ€åŒºåŸŸåœ¨æ—¶é—´ç»´åº¦ä¸Šå–å¹³å‡
- **ç©ºé—´èšç±»**: ä½¿ç”¨DPC-KNNç®—æ³•åˆå¹¶ç©ºé—´ä¸Šç›¸ä¼¼çš„token

### Stage 2: åŸºäºæ³¨æ„åŠ›çš„Tokené€‰æ‹© (Attention-based Token Selection)

åˆ©ç”¨LLMçš„æ³¨æ„åŠ›æœºåˆ¶ä¿ç•™ä¸é—®é¢˜ç›¸å…³çš„tokenï¼š
- åœ¨LLMçš„ä¸­é—´å±‚ï¼ˆé»˜è®¤ç¬¬10å±‚ï¼‰æå–æ³¨æ„åŠ›æƒé‡
- è®¡ç®—é—®é¢˜tokenåˆ°è§†è§‰tokençš„äº¤å‰æ³¨æ„åŠ›
- ä½¿ç”¨max-maxç­–ç•¥è®¡ç®—æ¯ä¸ªè§†è§‰tokençš„é‡è¦æ€§
- ä¿ç•™top-Î±%ï¼ˆé»˜è®¤40%ï¼‰æœ€é‡è¦çš„token

### Stage 3: KVç¼“å­˜å‹ç¼© (KV Cache Compression)

åœ¨ç”Ÿæˆé˜¶æ®µå‡å°‘å†…å­˜å’Œè®¡ç®—ï¼š
- å‹ç¼©å‰Må±‚çš„KV cacheï¼Œåªä¿ç•™é€‰ä¸­çš„token
- åç»­å±‚è‡ªåŠ¨ä½¿ç”¨å‹ç¼©åçš„åºåˆ—

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python >= 3.8
- PyTorch >= 2.0
- CUDA >= 11.7 (æ¨è)

### å®‰è£…ä¾èµ–

```bash
cd /mnt/ssd_ext/huggingface/prunevid_qwen_new

# å®‰è£…transformerså’Œç›¸å…³åº“
pip install transformers>=4.40.0
pip install accelerate
pip install qwen-vl-utils  # Qwen2.5-VLçš„å·¥å…·åº“
pip install opencv-python  # è§†é¢‘å¤„ç†
pip install pillow
```

### æ¨¡å‹ä¸‹è½½

```python
from transformers import Qwen2VLForConditionalGeneration

# ä¼šè‡ªåŠ¨ä»HuggingFaceä¸‹è½½
model_path = "Qwen/Qwen2.5-VL-7B-Instruct"
```

æˆ–è€…æ‰‹åŠ¨ä¸‹è½½åˆ°æœ¬åœ°ï¼š
```bash
# ä½¿ç”¨huggingface-cli
huggingface-cli download Qwen/Qwen2.5-VL-7B-Instruct --local-dir ./models/qwen2.5-vl-7b
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ä½¿ç”¨

```python
from prunevid_qwen_new import PruneVidQwen25VL, get_paper_config

# 1. åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨è®ºæ–‡æ¨èé…ç½®ï¼‰
model = PruneVidQwen25VL(
    model_path="Qwen/Qwen2.5-VL-7B-Instruct",
    config=get_paper_config(),
    device="cuda",
)

# 2. å¯¹è§†é¢‘æé—®
result = model.generate(
    video_path="path/to/your/video.mp4",
    question="è§†é¢‘ä¸­å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ",
    max_new_tokens=512,
)

# 3. æŸ¥çœ‹ç»“æœ
print(f"å›ç­”: {result['answer']}")
print(f"Tokenå‹ç¼©ç‡: {result['stats']['stage1']['reduction_percentage']:.1f}%")
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
python demo.py \
    --video_path /path/to/video.mp4 \
    --question "æè¿°è§†é¢‘ä¸­çš„ä¸»è¦äº‹ä»¶" \
    --config paper \
    --verbose
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨

### ä½¿ç”¨ä¸åŒçš„é…ç½®

PruneVidæä¾›äº†4ç§é¢„è®¾é…ç½®ï¼š

```python
from prunevid_qwen_new import (
    get_baseline_config,      # æ— å‰ªæï¼ˆbaselineï¼‰
    get_paper_config,         # è®ºæ–‡æ¨èé…ç½®
    get_conservative_config,  # é«˜å‹ç¼©ï¼ˆæ›´å¿«ï¼Œå‡†ç¡®ç‡ç•¥é™ï¼‰
    get_aggressive_config,    # ä½å‹ç¼©ï¼ˆæ›´å‡†ç¡®ï¼Œé€Ÿåº¦é€‚ä¸­ï¼‰
)

# ä½¿ç”¨é«˜å‹ç¼©é…ç½®
model = PruneVidQwen25VL(config=get_conservative_config())
```

### è‡ªå®šä¹‰é…ç½®

```python
from prunevid_qwen_new import PruneVidConfig

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
custom_config = PruneVidConfig(
    # Stage 1å‚æ•°
    tau=0.8,                    # é™æ€/åŠ¨æ€åˆ†ç¦»é˜ˆå€¼
    cluster_ratio=0.5,          # ç©ºé—´èšç±»ä¿ç•™æ¯”ä¾‹
    temporal_segment_ratio=0.25,# æ—¶åºåˆ†æ®µæ¯”ä¾‹
    dpc_knn_k=5,               # DPC-KNNçš„Kå€¼
    enable_stage1=True,

    # Stage 2å‚æ•°
    keep_ratio=0.4,            # tokenä¿ç•™æ¯”ä¾‹ï¼ˆÎ±ï¼‰
    pruning_layer=10,          # å‰ªæå±‚ç´¢å¼•
    attention_aggregation="max",# æ³¨æ„åŠ›èšåˆç­–ç•¥
    enable_stage2=True,

    # Stage 3å‚æ•°
    enable_cache_compression=True,

    # è°ƒè¯•
    verbose=True,              # è¾“å‡ºè¯¦ç»†æ—¥å¿—
    collect_stats=True,        # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
)

model = PruneVidQwen25VL(config=custom_config)
```

### æ¶ˆèå®éªŒ

åªå¯ç”¨æŸäº›é˜¶æ®µï¼š

```python
# åªå¯ç”¨Stage 1
from prunevid_qwen_new import get_stage1_only_config
model = PruneVidQwen25VL(config=get_stage1_only_config())

# æˆ–æ‰‹åŠ¨é…ç½®
config = PruneVidConfig(
    enable_stage1=True,
    enable_stage2=False,
    enable_cache_compression=False,
)
```

### å¤„ç†å›¾ç‰‡

PruneVidä¹Ÿå¯ä»¥ç”¨äºå›¾ç‰‡ç†è§£ï¼š

```python
result = model.generate(
    images=["image1.jpg", "image2.jpg"],
    question="æ¯”è¾ƒè¿™ä¸¤å¼ å›¾ç‰‡çš„å·®å¼‚ã€‚",
)
```

### è·å–è¯¦ç»†ç»Ÿè®¡

```python
result = model.generate(
    video_path="video.mp4",
    question="...",
    return_stats=True,
)

# è®¿é—®å„é˜¶æ®µç»Ÿè®¡
stats = result['stats']

# Stage 1
print(f"Stage 1å‹ç¼©: {stats['stage1']['original_tokens']} -> {stats['stage1']['compressed_tokens']}")
print(f"é™æ€tokenæ¯”ä¾‹: {stats['stage1']['static_ratio']:.1%}")

# Stage 2
print(f"Stage 2å‹ç¼©: {stats['stage2']['original_tokens']} -> {stats['stage2']['compressed_tokens']}")

# Stage 3
print(f"KV cacheå‹ç¼©: {stats['stage3']['reduction_ratio']:.1%}")
```

## ğŸ“Š æ€§èƒ½

åŸºäºACL 2025è®ºæ–‡åœ¨PLLaVAä¸Šçš„ç»“æœï¼ˆQwen2.5-VLçš„æ€§èƒ½ç±»ä¼¼ï¼‰ï¼š

| æ–¹æ³• | Tokenä¿ç•™ç‡ | FLOPs | MVBench | VideoMME | EgoSchema |
|------|-------------|-------|---------|----------|-----------|
| Baseline | 100% | 1.00Ã— | 46.6 | 44.4 | 47.8/42.6 |
| **PruneVid** | **16.2%** | **0.23Ã—** | **47.6** | **45.0** | **49.0/42.6** |

**å…³é”®ä¼˜åŠ¿ï¼š**
- âœ… Tokenå‡å°‘83.8%
- âœ… FLOPså‡å°‘77%
- âœ… å‡†ç¡®ç‡ä¿æŒæˆ–æå‡
- âœ… å†…å­˜å ç”¨é™ä½
- âœ… æ¨ç†é€Ÿåº¦æå‡1.5-2.0Ã—

## âš™ï¸ é…ç½®å‚æ•°

### Stage 1å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `tau` | 0.8 | é™æ€tokenæ£€æµ‹é˜ˆå€¼ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰ |
| `cluster_ratio` | 0.5 | ç©ºé—´èšç±»åä¿ç•™æ¯”ä¾‹ |
| `temporal_segment_ratio` | 0.25 | æ—¶åºåˆ†æ®µçš„æ¯”ä¾‹ |
| `dpc_knn_k` | 5 | DPC-KNNç®—æ³•çš„Kå€¼ |

### Stage 2å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `keep_ratio` | 0.4 | Tokenä¿ç•™æ¯”ä¾‹ï¼ˆÎ±ï¼‰ |
| `pruning_layer` | 10 | æ‰§è¡Œå‰ªæçš„å±‚ï¼ˆå¯¹28å±‚æ¨¡å‹ï¼‰ |
| `attention_aggregation` | "max" | æ³¨æ„åŠ›èšåˆç­–ç•¥ï¼šmaxæˆ–mean |

### Stage 3å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `enable_cache_compression` | True | æ˜¯å¦å¯ç”¨KVç¼“å­˜å‹ç¼© |

### è§†é¢‘å¤„ç†å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `max_frames` | 16 | æœ€å¤§é‡‡æ ·å¸§æ•° |
| `video_sampling` | "uniform" | é‡‡æ ·æ–¹å¼ï¼šuniformæˆ–fps |

## ğŸ“ é¡¹ç›®ç»“æ„

```
prunevid_qwen_new/
â”œâ”€â”€ __init__.py                          # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ config.py                            # é…ç½®ç±»å’Œé¢„è®¾é…ç½®
â”œâ”€â”€ utils.py                             # å·¥å…·å‡½æ•°ï¼ˆDPC-KNNç­‰ï¼‰
â”œâ”€â”€ stage1_temporal_spatial_merge.py     # Stage 1å®ç°
â”œâ”€â”€ stage2_attention_selection.py        # Stage 2å®ç°
â”œâ”€â”€ stage3_kv_cache.py                   # Stage 3å®ç°
â”œâ”€â”€ modeling_qwen2_5_vl_prunevid.py     # é›†æˆæ¨¡å‹
â”œâ”€â”€ model_wrapper.py                     # é«˜å±‚API
â”œâ”€â”€ demo.py                              # æ¼”ç¤ºè„šæœ¬
â””â”€â”€ README.md                            # æœ¬æ–‡æ¡£
```

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### Stage 1: æ—¶ç©ºåˆå¹¶

1. **æ—¶åºèšç±»**:
   - ä½¿ç”¨DPC-KNNå°†å¸§èšç±»æˆåœºæ™¯æ®µ
   - ç¡®ä¿åŒä¸€åœºæ™¯çš„å¸§æ˜¯è¿ç»­çš„

2. **é™æ€/åŠ¨æ€åˆ†ç¦»**:
   - è®¡ç®—æ¯ä¸ªç©ºé—´ä½ç½®åœ¨æ—¶é—´ç»´åº¦ä¸Šçš„ä½™å¼¦ç›¸ä¼¼åº¦
   - ç›¸ä¼¼åº¦ â‰¥ Ï„ çš„ä½ç½®æ ‡è®°ä¸ºé™æ€

3. **tokenåˆå¹¶**:
   - é™æ€tokenï¼šæ—¶åºå¹³å‡ + ç©ºé—´èšç±»
   - åŠ¨æ€tokenï¼šæ¯å¸§ç‹¬ç«‹ç©ºé—´èšç±»

### Stage 2: æ³¨æ„åŠ›é€‰æ‹©

1. **æ³¨æ„åŠ›æå–**:
   - åœ¨ç¬¬Må±‚ä½¿ç”¨forward hook
   - æå–é—®é¢˜â†’è§†è§‰çš„äº¤å‰æ³¨æ„åŠ›çŸ©é˜µ

2. **é‡è¦æ€§è®¡ç®—**:
   - Max-maxç­–ç•¥ï¼šå…ˆå¯¹é—®é¢˜tokenså–maxï¼Œå†å¯¹attention headså–max

3. **tokené€‰æ‹©**:
   - æŒ‰é‡è¦æ€§æ’åºï¼Œä¿ç•™top Î±%

### Stage 3: KVç¼“å­˜å‹ç¼©

1. **å‹ç¼©æ—¶æœº**: Stage 2å®Œæˆåç«‹å³å‹ç¼©å‰Må±‚
2. **å‹ç¼©æ–¹æ³•**: åªä¿ç•™é€‰ä¸­tokençš„KVå‘é‡
3. **æ•ˆæœ**: å‡å°‘å†…å­˜ï¼ŒåŠ é€Ÿåç»­å±‚è®¡ç®—

## ğŸ› å·²çŸ¥é—®é¢˜å’Œé™åˆ¶

1. **Batch sizeé™åˆ¶**: å½“å‰å®ç°åªæ”¯æŒbatch_size=1
2. **Stage 1å®Œæ•´é›†æˆ**: ç”±äºQwen2.5-VLæ¶æ„é™åˆ¶ï¼ŒStage 1éœ€è¦é€šè¿‡processoré¢„å¤„ç†å®ç°
3. **å¤šè§†é¢‘å¤„ç†**: æš‚ä¸æ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªè§†é¢‘

## ğŸ”® æœªæ¥æ”¹è¿›

- [ ] æ”¯æŒbatch_size > 1
- [ ] å®Œæ•´çš„Stage 1é›†æˆï¼ˆä¿®æ”¹æ¨¡å‹å†…éƒ¨forwardï¼‰
- [ ] æ·»åŠ æ›´å¤šè¯„ä¼°è„šæœ¬ï¼ˆMVBench, VideoMMEç­‰ï¼‰
- [ ] ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨
- [ ] æ”¯æŒæ›´å¤šVideo LLMï¼ˆLLaVA-Video, VideoChatç­‰ï¼‰

## ğŸ“ å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†è¿™ä¸ªå®ç°ï¼Œè¯·å¼•ç”¨åŸå§‹è®ºæ–‡ï¼š

```bibtex
@inproceedings{huang2025prunevid,
  title={PruneVid: Visual Token Pruning for Efficient Video Large Language Models},
  author={Huang, Xiaohu and Zhou, Hao and Han, Kai},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={19959--19973},
  year={2025}
}
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªApache 2.0è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- [PruneVidè®ºæ–‡ä½œè€…](https://github.com/Visual-AI/PruneVid)
- [Qwen2.5-VL](https://github.com/QwenLM/Qwen2-VL)
- [Transformers](https://github.com/huggingface/transformers)

## ğŸ’¬ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æissueæˆ–è”ç³»ï¼š
- Email: your-email@example.com
- GitHub: https://github.com/your-repo/prunevid-qwen

---

**æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªç ”ç©¶å®ç°ï¼Œä¸»è¦ç”¨äºå­¦æœ¯ç ”ç©¶å’Œæ–¹æ³•éªŒè¯ã€‚ç”Ÿäº§ç¯å¢ƒä½¿ç”¨è¯·å……åˆ†æµ‹è¯•ã€‚

"""
EgoSchemaËØÑ‰º∞ËÑöÊú¨ - PruneVid for Qwen2.5-VL (Êñ∞ÂÆûÁé∞)

Âú®EgoSchemaÊï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞PruneVidÊñπÊ≥ïÁöÑÊÄßËÉΩÂíåtokenÂéãÁº©ÊïàÊûú
"""

import os
import json
import torch
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Optional
import time
from datasets import load_dataset

# ============================================================================
# ÂèØË∞ÉË∂ÖÂèÇÊï∞ÈÖçÁΩÆÂå∫Âüü
# ============================================================================

# GPUÈÖçÁΩÆ
GPU_ID = 2 # ‰ΩøÁî®Âì™ÂùóGPUÔºà0, 1, 2, ...Ôºâ
DEVICE = f"cuda:{GPU_ID}"

# Êï∞ÊçÆÈõÜÈÖçÁΩÆ
VIDEO_DIR = "/mnt/ssd_ext/huggingface/egoschema/videos"  # ËßÜÈ¢ëÊñá‰ª∂Â§π
# ‰ΩøÁî®datasetsÂ∫ìÂä†ËΩΩEgoSchemaÊï∞ÊçÆÈõÜ
DATASET_NAME = "lmms-lab/egoschema"
DATASET_SPLIT = "test"  # 'test' or 'validation'

# Ê®°ÂûãÈÖçÁΩÆ
MODEL_PATH = "Qwen/Qwen2.5-VL-7B-Instruct"  # Qwen2.5-VLÊ®°ÂûãË∑ØÂæÑÔºàÂèØ‰ª•ÊòØHF IDÊàñÊú¨Âú∞Ë∑ØÂæÑÔºâ

# PruneVidÈÖçÁΩÆÊ®°Âºè
CONFIG_MODE = "custom"  # ÂèØÈÄâ: "baseline", "paper", "conservative", "aggressive", "custom"

# Ëá™ÂÆö‰πâÈÖçÁΩÆÔºà‰ªÖÂΩìCONFIG_MODE="custom"Êó∂‰ΩøÁî®Ôºâ
# Stage 1: Êó∂Á©∫TokenÂêàÂπ∂
CUSTOM_ENABLE_STAGE1 = False
CUSTOM_TAU = 0.8  # ÈùôÊÄÅ/Âä®ÊÄÅÂàÜÁ¶ªÈòàÂÄº (0.6-0.9)
CUSTOM_CLUSTER_RATIO = 0.5  # Á©∫Èó¥ËÅöÁ±ª‰øùÁïôÊØî‰æã (0.3-0.7)
CUSTOM_TEMPORAL_SEGMENT_RATIO = 0.25  # Êó∂Â∫èÂàÜÊÆµÊØî‰æã (0.125-0.5)
CUSTOM_DPC_KNN_K = 5  # DPC-KNNÁöÑkËøëÈÇªÂèÇÊï∞

# Stage 2: Âü∫‰∫éÊ≥®ÊÑèÂäõÁöÑTokenÈÄâÊã©
CUSTOM_ENABLE_STAGE2 = False   
CUSTOM_KEEP_RATIO = 0.3  # Token‰øùÁïôÊØî‰æã (0.2-0.6)
CUSTOM_PRUNING_LAYER = 10  # Âú®Âì™‰∏ÄÂ±ÇËøõË°åÂâ™Êûù (5-15)
CUSTOM_ATTENTION_AGGREGATION = "max"  # 'max' or 'mean'

# Stage 3: KVÁºìÂ≠òÂéãÁº©
CUSTOM_ENABLE_CACHE_COMPRESSION = False

# ËßÜÈ¢ëÂ§ÑÁêÜÈÖçÁΩÆ
MAX_FRAMES = 16  # ÊúÄÂ§ßÂ∏ßÊï∞ (8, 16, 32)

# ÁîüÊàêÈÖçÁΩÆ
MAX_NEW_TOKENS = 10  # ÁªôÊ®°ÂûãÂÖÖÂàÜÁ©∫Èó¥Ëß£ÈáäÁ≠îÊ°àÔºàÂéªÊéâÈôêÂà∂Ôºâ
TEMPERATURE = 0.0  # 0Ë°®Á§∫greedy decoding
DO_SAMPLE = False

# ÊµãËØïÈÖçÁΩÆ
NUM_SAMPLES = 500  # ÊµãËØïÊ†∑Êú¨Êï∞ÈáèÔºåNoneË°®Á§∫ÂÖ®ÈÉ®
START_INDEX = 0  # ‰ªéÁ¨¨Âá†‰∏™Ê†∑Êú¨ÂºÄÂßã
SAVE_RESULTS = True  # ÊòØÂê¶‰øùÂ≠òÁªìÊûú
OUTPUT_DIR = "./results"  # ÁªìÊûú‰øùÂ≠òÁõÆÂΩï
VERBOSE = True  # ÊòØÂê¶ÊâìÂç∞ËØ¶ÁªÜ‰ø°ÊÅØ

# ============================================================================
# ‰ª£Á†ÅÂºÄÂßã
# ============================================================================

# ËÆæÁΩÆCUDAËÆæÂ§á
if torch.cuda.is_available():
    torch.cuda.set_device(GPU_ID)

import sys
sys.path.insert(0, str(Path(__file__).parent))

from config import (
    PruneVidConfig,
    get_baseline_config,
    get_paper_config,
    get_conservative_config,
    get_aggressive_config
)
from model_wrapper import PruneVidQwen25VL


class EgoSchemaEvaluator:
    """EgoSchemaËØÑ‰º∞Âô®"""

    def __init__(
        self,
        model: PruneVidQwen25VL,
        video_dir: str,
        dataset_name: str = "lmms-lab/egoschema",
        dataset_split: str = "test",
    ):
        self.model = model
        self.video_dir = Path(video_dir)
        self.dataset_name = dataset_name
        self.dataset_split = dataset_split

        # Âä†ËΩΩÊï∞ÊçÆÈõÜ
        self.load_dataset()

        # ÁªüËÆ°‰ø°ÊÅØ
        self.total_samples = 0
        self.correct_samples = 0
        self.total_tokens_before = 0
        self.total_tokens_after_stage1 = 0
        self.total_tokens_after_stage2 = 0
        self.total_tokens_after = 0
        self.results = []

    def load_dataset(self):
        """Âä†ËΩΩEgoSchemaÊï∞ÊçÆÈõÜ"""
        print(f"Loading dataset {self.dataset_name} ({self.dataset_split})...")
        self.dataset = load_dataset(self.dataset_name, "Subset", split=self.dataset_split)
        print(f"Loaded {len(self.dataset)} questions")

    def format_question(self, sample: Dict) -> str:
        """
        Ê†ºÂºèÂåñÈóÆÈ¢ò‰∏∫ÈÄâÊã©È¢òÂΩ¢Âºè

        Args:
            sample: Ê†áÊ≥®Ê†∑Êú¨

        Returns:
            formatted_question: Ê†ºÂºèÂåñÂêéÁöÑÈóÆÈ¢ò
        """
        question = sample['question']
        options = sample['option']  # options is already a list

        formatted = f"{question}\n\n"
        formatted += "Options:\n"
        for i, opt in enumerate(options):
            formatted += f"{i}. {opt}\n"
        formatted += "\nAnswer with the option number (0-4):"

        return formatted

    def extract_answer(self, generated_text: str) -> Optional[int]:
        """
        ‰ªéÁîüÊàêÁöÑÊñáÊú¨‰∏≠ÊèêÂèñÁ≠îÊ°àÈÄâÈ°π

        Args:
            generated_text: Ê®°ÂûãÁîüÊàêÁöÑÊñáÊú¨

        Returns:
            answer: Á≠îÊ°àÈÄâÈ°π (0-4)ÔºåÂ¶ÇÊûúÊó†Ê≥ïÊèêÂèñÂàôËøîÂõûNone
        """
        # Ê∏ÖÁêÜÊñáÊú¨
        text = generated_text.strip().lower()

        # Â∞ùËØïÂ§öÁßçÊèêÂèñÊñπÂºè
        # 1. Áõ¥Êé•ÊòØÊï∞Â≠ó
        if text in ['0', '1', '2', '3', '4']:
            return int(text)

        # 2. Â≠óÊØçÂΩ¢Âºè (A=0, B=1, C=2, D=3, E=4)
        if text.startswith('a') or text.startswith('option a'):
            return 0
        elif text.startswith('b') or text.startswith('option b'):
            return 1
        elif text.startswith('c') or text.startswith('option c'):
            return 2
        elif text.startswith('d') or text.startswith('option d'):
            return 3
        elif text.startswith('e') or text.startswith('option e'):
            return 4

        # 3. ÂåÖÂê´"option X"Êàñ"ÈÄâÈ°π X"
        for i in range(5):
            if f"option {i}" in text or f"ÈÄâÈ°π {i}" in text or f"option{i}" in text:
                return i

        # 4. Êü•ÊâæÂ≠óÊØçÈÄâÈ°π
        letter_map = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}
        for char in text:
            if char in letter_map:
                return letter_map[char]

        # 5. Êü•ÊâæÊï∞Â≠ó0-4
        for char in text:
            if char in '01234':
                return int(char)

        # 6. Êó†Ê≥ïÊèêÂèñ
        return None

    def evaluate_sample(self, sample: Dict, sample_idx: int) -> Optional[Dict]:
        """
        ËØÑ‰º∞Âçï‰∏™Ê†∑Êú¨

        Args:
            sample: Ê†áÊ≥®Ê†∑Êú¨
            sample_idx: Ê†∑Êú¨Á¥¢Âºï

        Returns:
            result: ËØÑ‰º∞ÁªìÊûú
        """
        # Ëé∑ÂèñËßÜÈ¢ëË∑ØÂæÑ
        video_id = sample['video_idx']
        video_path = self.video_dir / f"{video_id}.mp4"

        if not video_path.exists():
            print(f"Warning: Video not found: {video_path}")
            return None

        # Ê†ºÂºèÂåñÈóÆÈ¢ò
        question = self.format_question(sample)

        # Ê®°ÂûãÊé®ÁêÜ
        try:
            result = self.model.generate(
                video_path=str(video_path),
                question=question,
                max_new_tokens=MAX_NEW_TOKENS,
                temperature=TEMPERATURE,
                do_sample=DO_SAMPLE,
                return_stats=True,
            )

            generated_text = result['answer']
            stats = result.get('stats', {})

            # ÊèêÂèñÁ≠îÊ°à
            predicted_answer = self.extract_answer(generated_text)
            ground_truth = int(sample['answer'])

            # Âà§Êñ≠Ê≠£Á°ÆÊÄß
            is_correct = (predicted_answer == ground_truth)

            # Ëé∑ÂèñtokenÁªüËÆ°
            # ‰ªéÊñ∞ÂÆûÁé∞ÁöÑstatsÊ†ºÂºè‰∏≠ÊèêÂèñ‰ø°ÊÅØ
            stage1_stats = stats.get('stage1', {})
            stage2_stats = stats.get('stage2', {})

            # Ëé∑ÂèñÂéüÂßãtokenÊï∞Èáè
            if stage1_stats:
                tokens_before = stage1_stats.get('original_tokens', 0)
                tokens_after_stage1 = stage1_stats.get('compressed_tokens', tokens_before)
            else:
                # Stage 1Á¶ÅÁî®Ôºå‰ΩøÁî®input_tokens‰Ωú‰∏∫ÂéüÂßãÂÄº
                tokens_before = result.get('input_tokens', 0)
                tokens_after_stage1 = tokens_before

            # Ëé∑ÂèñStage 2ÂêéÁöÑtokenÊï∞Èáè
            if stage2_stats:
                # Stage 2ÂêØÁî®Ôºå‰ΩøÁî®ÂÖ∂ÂéãÁº©ÂêéÁöÑÂÄº
                tokens_after_stage2 = stage2_stats.get('compressed_tokens', tokens_after_stage1)
            else:
                # Stage 2Á¶ÅÁî®Ôºå‰øùÊåÅStage 1ÁöÑÂÄº
                tokens_after_stage2 = tokens_after_stage1

            # ËøîÂõûÁªìÊûú
            return {
                'sample_idx': sample_idx,
                'video_id': video_id,
                'question': sample['question'],
                'ground_truth': ground_truth,
                'predicted_answer': predicted_answer,
                'generated_text': generated_text,
                'is_correct': is_correct,
                'tokens_before': tokens_before,
                'tokens_after_stage1': tokens_after_stage1,
                'tokens_after_stage2': tokens_after_stage2,
                'tokens_after': tokens_after_stage2,
                'stats': stats,
            }

        except Exception as e:
            print(f"Error processing sample {sample_idx}: {e}")
            import traceback
            traceback.print_exc()
            return None

    def print_sample_result(self, result: Dict, total_samples: int):
        """ÊâìÂç∞Âçï‰∏™Ê†∑Êú¨ÁöÑÁªìÊûú"""
        # ÊâìÂç∞Ê†∑Êú¨‰ø°ÊÅØÔºàÈóÆÈ¢òÁºñÂè∑„ÄÅËßÜÈ¢ëID„ÄÅÈóÆÈ¢òÔºâ
        print(f"Sample {result['sample_idx'] + 1}/{total_samples}")
        print(f"Video ID: {result['video_id']}")
        print(f"Question: {result['question'][:100]}...")
        print()

        # ËØ¶ÁªÜÂ§ÑÁêÜËøáÁ®ãÂíåÂéãÁº©ÁªüËÆ°‰ºöÂú®ËøôÈáåËá™Âä®ÊâìÂç∞ÔºàÁî±Ê®°ÂûãÁöÑverboseËæìÂá∫Ôºâ

        # ÊâìÂç∞È¢ÑÊµãÁªìÊûú
        print(f"\nGround Truth: {result['ground_truth']}")
        print(f"Predicted:    {result['predicted_answer']}")
        print(f"Correct: {'‚úì' if result['is_correct'] else '‚úó'}")

        # ÂΩìÂâçÁ¥ØËÆ°ÂáÜÁ°ÆÁéá
        accuracy = self.correct_samples / self.total_samples * 100
        print(f"\nüìä Current Accuracy: {self.correct_samples}/{self.total_samples} = {accuracy:.2f}%")

        # TokenÂéãÁº©ÁªüËÆ°
        tokens_before = result['tokens_before']
        tokens_after_stage1 = result['tokens_after_stage1']
        tokens_after_stage2 = result['tokens_after_stage2']

        stage1_drop = (tokens_before - tokens_after_stage1) / tokens_before * 100 if tokens_before > 0 else 0
        stage2_drop = (tokens_after_stage1 - tokens_after_stage2) / tokens_after_stage1 * 100 if tokens_after_stage1 > 0 else 0
        total_drop = (tokens_before - tokens_after_stage2) / tokens_before * 100 if tokens_before > 0 else 0

        print(f"\nüìâ Token Compression (Current Sample):")
        print(f"  Original:      {tokens_before}")
        print(f"  After Stage 1: {tokens_after_stage1} (drop: {stage1_drop:.1f}%)")
        print(f"  After Stage 2: {tokens_after_stage2} (drop: {stage2_drop:.1f}%)")
        print(f"  Total drop:    {total_drop:.1f}%")

        # Á¥ØËÆ°Âπ≥ÂùáÂéãÁº©Áéá
        avg_stage1_drop = (self.total_tokens_before - self.total_tokens_after_stage1) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0
        avg_stage2_drop = (self.total_tokens_after_stage1 - self.total_tokens_after_stage2) / self.total_tokens_after_stage1 * 100 if self.total_tokens_after_stage1 > 0 else 0
        avg_total_drop = (self.total_tokens_before - self.total_tokens_after_stage2) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0

        print(f"\nüìâ Average Token Compression (Cumulative):")
        print(f"  Stage 1 avg drop: {avg_stage1_drop:.1f}%")
        print(f"  Stage 2 avg drop: {avg_stage2_drop:.1f}%")
        print(f"  Total avg drop:   {avg_total_drop:.1f}%")

        # ÈóÆÈ¢ò‰πãÈó¥ÁöÑÂàÜÂâ≤Á∫ø
        print(f"\n{'='*80}\n")

    def run_evaluation(
        self,
        num_samples: Optional[int] = None,
        start_index: int = 0,
    ):
        """
        ËøêË°åËØÑ‰º∞

        Args:
            num_samples: ËØÑ‰º∞Ê†∑Êú¨Êï∞ÈáèÔºåNoneË°®Á§∫ÂÖ®ÈÉ®
            start_index: Ëµ∑ÂßãÁ¥¢Âºï
        """
        # Á°ÆÂÆöË¶ÅËØÑ‰º∞ÁöÑÊ†∑Êú¨
        end_index = len(self.dataset) if num_samples is None else min(start_index + num_samples, len(self.dataset))
        samples_to_eval = self.dataset.select(range(start_index, end_index))

        print(f"\n{'='*80}")
        print(f"Starting evaluation on {len(samples_to_eval)} samples (from index {start_index})")
        print(f"{'='*80}\n")

        # ËØÑ‰º∞ÊØè‰∏™Ê†∑Êú¨
        start_time = time.time()

        for i, sample in enumerate(samples_to_eval):
            sample_idx = start_index + i
            total_samples_count = len(samples_to_eval)

            # Âú®ËØÑ‰º∞ÂâçÊâìÂç∞Ê†∑Êú¨Â§¥‰ø°ÊÅØ
            if VERBOSE:
                print(f"Sample {i + 1}/{total_samples_count}")
                print(f"Video ID: {sample['video_idx']}")
                print(f"Question: {sample['question'][:100]}...")
                print()

            # ËØÑ‰º∞Ê†∑Êú¨
            result = self.evaluate_sample(sample, sample_idx)

            if result is None:
                continue

            # Êõ¥Êñ∞ÁªüËÆ°
            self.total_samples += 1
            if result['is_correct']:
                self.correct_samples += 1

            self.total_tokens_before += result['tokens_before']
            self.total_tokens_after_stage1 += result['tokens_after_stage1']
            self.total_tokens_after_stage2 += result['tokens_after_stage2']
            self.total_tokens_after += result['tokens_after']

            self.results.append(result)

            # ÊâìÂç∞ÁªìÊûúÔºà‰∏çÂÜçÊâìÂç∞Ê†∑Êú¨Â§¥‰ø°ÊÅØÔºåÂõ†‰∏∫Â∑≤ÁªèÂú®ÂâçÈù¢ÊâìÂç∞‰∫ÜÔºâ
            if VERBOSE:
                # ÊâìÂç∞È¢ÑÊµãÁªìÊûúÂíåÁªüËÆ°‰ø°ÊÅØ
                print(f"\nGround Truth: {result['ground_truth']}")
                print(f"Predicted:    {result['predicted_answer']}")
                print(f"Generated:    '{result['generated_text']}'")  # ÊòæÁ§∫ÂÆûÈôÖÁîüÊàêÁöÑÊñáÊú¨
                print(f"Correct: {'‚úì' if result['is_correct'] else '‚úó'}")

                # ÂΩìÂâçÁ¥ØËÆ°ÂáÜÁ°ÆÁéá
                accuracy = self.correct_samples / self.total_samples * 100
                print(f"\nüìä Current Accuracy: {self.correct_samples}/{self.total_samples} = {accuracy:.2f}%")

                # TokenÂéãÁº©ÁªüËÆ°
                tokens_before = result['tokens_before']
                tokens_after_stage1 = result['tokens_after_stage1']
                tokens_after_stage2 = result['tokens_after_stage2']

                stage1_drop = (tokens_before - tokens_after_stage1) / tokens_before * 100 if tokens_before > 0 else 0
                stage2_drop = (tokens_after_stage1 - tokens_after_stage2) / tokens_after_stage1 * 100 if tokens_after_stage1 > 0 else 0
                total_drop = (tokens_before - tokens_after_stage2) / tokens_before * 100 if tokens_before > 0 else 0

                print(f"\nüìâ Token Compression (Current Sample):")
                print(f"  Original:      {tokens_before}")
                print(f"  After Stage 1: {tokens_after_stage1} (drop: {stage1_drop:.1f}%)")
                print(f"  After Stage 2: {tokens_after_stage2} (drop: {stage2_drop:.1f}%)")
                print(f"  Total drop:    {total_drop:.1f}%")

                # Á¥ØËÆ°Âπ≥ÂùáÂéãÁº©Áéá
                avg_stage1_drop = (self.total_tokens_before - self.total_tokens_after_stage1) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0
                avg_stage2_drop = (self.total_tokens_after_stage1 - self.total_tokens_after_stage2) / self.total_tokens_after_stage1 * 100 if self.total_tokens_after_stage1 > 0 else 0
                avg_total_drop = (self.total_tokens_before - self.total_tokens_after_stage2) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0

                print(f"\nüìâ Average Token Compression (Cumulative):")
                print(f"  Stage 1 avg drop: {avg_stage1_drop:.1f}%")
                print(f"  Stage 2 avg drop: {avg_stage2_drop:.1f}%")
                print(f"  Total avg drop:   {avg_total_drop:.1f}%")

                # ÈóÆÈ¢ò‰πãÈó¥ÁöÑÂàÜÂâ≤Á∫ø
                print(f"\n{'='*80}\n")

        total_time = time.time() - start_time

        # ÊâìÂç∞ÊúÄÁªàÁªìÊûú
        self.print_final_results(total_time)

    def print_final_results(self, total_time: float):
        """ÊâìÂç∞ÊúÄÁªàËØÑ‰º∞ÁªìÊûú"""
        print(f"\n{'='*80}")
        print(f"üéâ EVALUATION COMPLETED")
        print(f"{'='*80}\n")

        # ÂáÜÁ°ÆÁéá
        accuracy = self.correct_samples / self.total_samples * 100 if self.total_samples > 0 else 0
        print(f"üìä Final Accuracy:")
        print(f"  Correct: {self.correct_samples}/{self.total_samples}")
        print(f"  Accuracy: {accuracy:.2f}%")

        # TokenÂéãÁº©ÁªüËÆ°
        avg_stage1_drop = (self.total_tokens_before - self.total_tokens_after_stage1) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0
        avg_stage2_drop = (self.total_tokens_after_stage1 - self.total_tokens_after_stage2) / self.total_tokens_after_stage1 * 100 if self.total_tokens_after_stage1 > 0 else 0
        avg_total_drop = (self.total_tokens_before - self.total_tokens_after_stage2) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0

        print(f"\nüìâ Final Token Compression:")
        print(f"  Total tokens before:       {self.total_tokens_before}")
        print(f"  Total tokens after Stage 1: {self.total_tokens_after_stage1}")
        print(f"  Total tokens after Stage 2: {self.total_tokens_after_stage2}")
        print(f"\n  Stage 1 drop ratio: {avg_stage1_drop:.2f}%")
        print(f"  Stage 2 drop ratio: {avg_stage2_drop:.2f}%")
        print(f"  Total drop ratio:   {avg_total_drop:.2f}%")

        # Êó∂Èó¥ÁªüËÆ°
        avg_time_per_sample = total_time / self.total_samples if self.total_samples > 0 else 0
        print(f"\n‚è±Ô∏è  Time Statistics:")
        print(f"  Total time: {total_time:.2f}s")
        print(f"  Avg time per sample: {avg_time_per_sample:.2f}s")

        print(f"\n{'='*80}\n")

        # ‰øùÂ≠òÁªìÊûú
        if SAVE_RESULTS:
            self.save_results()

    def save_results(self):
        """‰øùÂ≠òËØÑ‰º∞ÁªìÊûú"""
        os.makedirs(OUTPUT_DIR, exist_ok=True)

        # ÁîüÊàêÊñá‰ª∂Âêç
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"egoschema_results_{timestamp}_{CONFIG_MODE}.json"
        filepath = os.path.join(OUTPUT_DIR, filename)

        # ÂáÜÂ§á‰øùÂ≠òÁöÑÊï∞ÊçÆ
        save_data = {
            'config': {
                'config_mode': CONFIG_MODE,
                'model_config': self.model.config.to_dict(),
                'max_frames': MAX_FRAMES,
                'num_samples': NUM_SAMPLES,
            },
            'summary': {
                'total_samples': self.total_samples,
                'correct_samples': self.correct_samples,
                'accuracy': self.correct_samples / self.total_samples * 100 if self.total_samples > 0 else 0,
                'stage1_drop_ratio': (self.total_tokens_before - self.total_tokens_after_stage1) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0,
                'stage2_drop_ratio': (self.total_tokens_after_stage1 - self.total_tokens_after_stage2) / self.total_tokens_after_stage1 * 100 if self.total_tokens_after_stage1 > 0 else 0,
                'total_drop_ratio': (self.total_tokens_before - self.total_tokens_after_stage2) / self.total_tokens_before * 100 if self.total_tokens_before > 0 else 0,
            },
            'results': self.results,
        }

        # ‰øùÂ≠ò
        with open(filepath, 'w') as f:
            json.dump(save_data, f, indent=2)

        print(f"‚úÖ Results saved to: {filepath}")


def main():
    """‰∏ªÂáΩÊï∞"""
    print(f"\n{'='*80}")
    print(f"EgoSchema Evaluation - PruneVid for Qwen2.5-VL (New Implementation)")
    print(f"{'='*80}\n")

    # ÂàõÂª∫ÈÖçÁΩÆ
    if CONFIG_MODE == "baseline":
        config = get_baseline_config()
        print("Using BASELINE config (no pruning)")
    elif CONFIG_MODE == "paper":
        config = get_paper_config()
        print("Using PAPER config (tau=0.8, keep_ratio=0.4)")
    elif CONFIG_MODE == "conservative":
        config = get_conservative_config()
        print("Using CONSERVATIVE config (high compression)")
    elif CONFIG_MODE == "aggressive":
        config = get_aggressive_config()
        print("Using AGGRESSIVE config (low compression)")
    elif CONFIG_MODE == "custom":
        config = PruneVidConfig(
            # Stage 1
            enable_stage1=CUSTOM_ENABLE_STAGE1,
            tau=CUSTOM_TAU,
            cluster_ratio=CUSTOM_CLUSTER_RATIO,
            temporal_segment_ratio=CUSTOM_TEMPORAL_SEGMENT_RATIO,
            dpc_knn_k=CUSTOM_DPC_KNN_K,
            # Stage 2
            enable_stage2=CUSTOM_ENABLE_STAGE2,
            keep_ratio=CUSTOM_KEEP_RATIO,
            pruning_layer=CUSTOM_PRUNING_LAYER,
            attention_aggregation=CUSTOM_ATTENTION_AGGREGATION,
            # Stage 3
            enable_cache_compression=CUSTOM_ENABLE_CACHE_COMPRESSION,
            # Video
            max_frames=MAX_FRAMES,
            # Debug
            verbose=VERBOSE,
            collect_stats=True,
        )
        print("Using CUSTOM config")
    else:
        raise ValueError(f"Unknown CONFIG_MODE: {CONFIG_MODE}")

    # Êõ¥Êñ∞max_frames
    config.max_frames = MAX_FRAMES

    # ÊâìÂç∞ÈÖçÁΩÆ
    print(f"\nConfiguration:")
    print(f"  GPU: {GPU_ID} (device: {DEVICE})")
    print(f"  Model: {MODEL_PATH}")
    print(f"  Dataset: {DATASET_NAME} ({DATASET_SPLIT})")
    print(f"  Video dir: {VIDEO_DIR}")
    print(f"\nPruneVid Settings:")
    print(f"  Stage 1: {'ON' if config.enable_stage1 else 'OFF'}")
    if config.enable_stage1:
        print(f"    - tau: {config.tau}")
        print(f"    - cluster_ratio: {config.cluster_ratio}")
        print(f"    - temporal_segment_ratio: {config.temporal_segment_ratio}")
    print(f"  Stage 2: {'ON' if config.enable_stage2 else 'OFF'}")
    if config.enable_stage2:
        print(f"    - keep_ratio: {config.keep_ratio}")
        print(f"    - pruning_layer: {config.pruning_layer}")
    print(f"  Stage 3: {'ON' if config.enable_cache_compression else 'OFF'}")
    print(f"\nTest Settings:")
    print(f"  Num samples: {NUM_SAMPLES if NUM_SAMPLES else 'All'}")
    print(f"  Start index: {START_INDEX}")
    print(f"  Max frames: {MAX_FRAMES}")
    print(f"\n{'='*80}\n")

    # Âä†ËΩΩÊ®°Âûã
    print("Loading model...")
    model = PruneVidQwen25VL(
        model_path=MODEL_PATH,
        config=config,
        device=DEVICE,
        torch_dtype=torch.bfloat16,
    )
    print("Model loaded!\n")

    # ÂàõÂª∫ËØÑ‰º∞Âô®
    evaluator = EgoSchemaEvaluator(
        model=model,
        video_dir=VIDEO_DIR,
        dataset_name=DATASET_NAME,
        dataset_split=DATASET_SPLIT,
    )

    # ËøêË°åËØÑ‰º∞
    evaluator.run_evaluation(
        num_samples=NUM_SAMPLES,
        start_index=START_INDEX,
    )


if __name__ == "__main__":
    main()
